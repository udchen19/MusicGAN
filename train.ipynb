{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "from pytorch_lightning.core import LightningModule\n",
    "from pytorch_lightning.trainer import Trainer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import muspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch, T, R, Z = 64, 16, 128, (1, 3)\n",
    "ch2, ch3, ch4, ch6, ch8, ch16, ch32 = ch * np.array([2, 3, 4, 6, 8, 16, 32])\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "gStep, dStep, smooth, L1, L2 = 2, 1, 0.05, 0.1, 0.01\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            # (1, 48, 128)\n",
    "            nn.Conv2d(1, ch, (128, 2), 2),\n",
    "            nn.BatchNorm2d(ch),\n",
    "            nn.LeakyReLU(0.2, inplace = True)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            # (ch, 1, 8)\n",
    "            nn.Conv2d(ch, ch2, (1, 4), 2),\n",
    "            nn.BatchNorm2d(ch2),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            # (ch2, 1, 3)\n",
    "        )\n",
    "        self.nn = nn.Linear(ch2 * 3, 1)\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        c1 = self.conv1(x)\n",
    "        x = self.conv2(c1)\n",
    "        x = x.view(batch_size, -1)\n",
    "        return self.nn(x).squeeze(), c1\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, ch, (128, 2), 2),\n",
    "            nn.BatchNorm2d(ch),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(ch, ch2, (1, 4), 2),\n",
    "            nn.BatchNorm2d(ch2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.deconv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ch4, ch2, (1, 4), 2),\n",
    "            nn.BatchNorm2d(ch2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.deconv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ch3, 1, (128, 2), 2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        c1 = self.conv1(x) # (ch, 1, 8)\n",
    "        c2 = self.conv2(c1) # (ch2, 1, 4)\n",
    "        z = (torch.randn(x.shape[0], ch2, *Z, device = device) +1) / 2\n",
    "        x = self.deconv1(torch.cat((z, c2), dim = 1)) # (ch4, 1, 3) => (ch2, 1, 4)\n",
    "        x = self.deconv2(torch.cat((x, c1), dim = 1)) # (ch6, 1, 4) => (ch3, 1, 8)\n",
    "        return x\n",
    "\n",
    "class GAN(LightningModule):\n",
    "    \n",
    "    def __init__(self, batch_size):\n",
    "        super().__init__()\n",
    "        self.G = Generator()\n",
    "        self.D = Discriminator()\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.ones = torch.ones(batch_size, device = device)\n",
    "        self.oneSmooth = torch.ones(batch_size, device = device) * (1 - smooth)\n",
    "        self.zeros = torch.ones(batch_size, device = device)\n",
    "        #self.automatic_optimization = False\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.G(z)\n",
    "\n",
    "    def gStep(self, batch):\n",
    "        x, px = batch\n",
    "        x, px = x.float().unsqueeze(1), px.float().unsqueeze(1)\n",
    "        Gz = self(px)\n",
    "        DGz, GzC1 = self.D(Gz)\n",
    "        Dx, xC1 = self.D(x)\n",
    "        return self.criterion(DGz, self.ones) + L1 * (x - Gz).norm(2) + L2 * (xC1 - GzC1).norm(2)\n",
    "\n",
    "    def dStep(self, batch):\n",
    "        x, px = batch\n",
    "        x, px = x.float().unsqueeze(1), px.float().unsqueeze(1)\n",
    "        Dx, xC1 = self.D(x)\n",
    "        Gz = self(px)\n",
    "        DGz, GzC1 = self.D(Gz)\n",
    "        self.log('dAcc', ((DGz < 0).sum() + (Dx > 0).sum()) / (2 * x.shape[0]), on_epoch = True, prog_bar = True, logger = True)\n",
    "        return self.criterion(Dx, self.oneSmooth) + self.criterion(DGz, self.zeros)\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        if optimizer_idx < gStep:\n",
    "            loss = self.gStep(batch)\n",
    "            self.log('gLoss', loss, on_epoch = True, prog_bar = True, logger = True)\n",
    "            return loss\n",
    "        else:\n",
    "            loss = self.dStep(batch)\n",
    "            self.log('dLoss', loss, on_epoch = True, prog_bar = True, logger = True)\n",
    "            return loss\n",
    "    '''\n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        self.G.eval()\n",
    "        nMusic = 10\n",
    "        nBar = 10\n",
    "        for i in range(10):\n",
    "            px = torch.randn(1, 1, R, T).float() * 2 - 1\n",
    "            bars = []\n",
    "            for _ in range(nBar):\n",
    "                bars.append(self(px.to(device)).detach().cpu())\n",
    "                px = bars[-1]\n",
    "            music = muspy.from_pianoroll_representation(\n",
    "                (torch.cat(tuple(bars), dim = 3).squeeze().squeeze() > 0.5).numpy().T,\n",
    "                resolution = 4,\n",
    "                encode_velocity = False\n",
    "            )\n",
    "            music.write(f'samples/{i + 1}.mid')\n",
    "        self.G.train()\n",
    "    '''\n",
    "\n",
    "    def configure_optimizers(self):  \n",
    "        gOpt = optim.AdamW(self.G.parameters(), lr = 0.0004)\n",
    "        dOpt = optim.AdamW(self.D.parameters(), lr = 0.0001)\n",
    "        return [gOpt] * gStep + [dOpt] * dStep, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ProcessedDataset(Dataset):\n",
    "    def __init__(self, G, I):\n",
    "        self.Gdata = G\n",
    "        self.Idata = I\n",
    "    def __len__(self):\n",
    "        return len(self.Gdata)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.Gdata[idx], self.Idata[idx]\n",
    "\n",
    "batch_size = 128\n",
    "dataset = torch.load(f'./GandI_len128_10240.pt')\n",
    "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAN(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params\n",
      "------------------------------------------------\n",
      "0 | G         | Generator         | 230 K \n",
      "1 | D         | Discriminator     | 50.1 K\n",
      "2 | criterion | BCEWithLogitsLoss | 0     \n",
      "------------------------------------------------\n",
      "280 K     Trainable params\n",
      "0         Non-trainable params\n",
      "280 K     Total params\n",
      "1.122     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810eac8c8e6e40d5920526ea76525fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs = 10000,\n",
    "    gpus = 1 if torch.cuda.is_available() else 0,\n",
    "    track_grad_norm = 2,\n",
    "    log_every_n_steps = 10\n",
    ")\n",
    "trainer.fit(model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testMod = model.G.to(device)\n",
    "testMod.eval()\n",
    "nMusic = 20\n",
    "nBar = 8\n",
    "for i in range(10):\n",
    "    px = (torch.randn(1, 1, R, T).float() + 1) / 2\n",
    "    bars = []\n",
    "    for _ in range(nBar):\n",
    "        bars.append(testMod(px.to(device)).detach().cpu())\n",
    "        px = bars[-1] * 0.9 + (bars[-2] if len(bars) > 1 else bars[-1]) * 0.09 + (bars[-3] if len(bars) > 2 else bars[-1]) * 0.01\n",
    "    music = muspy.from_pianoroll_representation(\n",
    "        (torch.cat(tuple(bars), dim = 3).squeeze().squeeze() > 0.5).numpy().T,\n",
    "        resolution = 4,\n",
    "        encode_velocity = False\n",
    "    )\n",
    "    music.write(f'./samples/{i + 1}.mid')\n",
    "torch.save(model, './model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
